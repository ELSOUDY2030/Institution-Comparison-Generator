{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ELSOUDY2030/Institution-Comparison-Generator/blob/main/InstitutionComparativeAnalysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "TJ-7brop2XD3",
        "outputId": "ca02265e-6bc2-488b-b2b3-fb460736b879"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.6)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.4)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "  Attempting uninstall: sentencepiece\n",
            "    Found existing installation: sentencepiece 0.1.99\n",
            "    Uninstalling sentencepiece-0.1.99:\n",
            "      Successfully uninstalled sentencepiece-0.1.99\n",
            "Successfully installed sentencepiece-0.2.0\n",
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.43.3-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.33.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (2.4.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.24.6)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (3.15.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2024.6.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.1.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->bitsandbytes) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2024.8.30)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->bitsandbytes) (1.3.0)\n",
            "Downloading bitsandbytes-0.43.3-py3-none-manylinux_2_24_x86_64.whl (137.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.5/137.5 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: bitsandbytes\n",
            "Successfully installed bitsandbytes-0.43.3\n",
            "Collecting streamlit\n",
            "  Downloading streamlit-1.38.0-py2.py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: numpy<3,>=1.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.26.4)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (24.1)\n",
            "Requirement already satisfied: pandas<3,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.1.4)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.4.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (14.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.8.0)\n",
            "Collecting tenacity<9,>=8.1.0 (from streamlit)\n",
            "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.12.2)\n",
            "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.3)\n",
            "Collecting watchdog<5,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-4.0.2-py3-none-manylinux2014_x86_64.whl.metadata (38 kB)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.1)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2024.8.30)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.16.1)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.5)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.20.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.3.0->streamlit) (1.16.0)\n",
            "Downloading streamlit-1.38.0-py2.py3-none-any.whl (8.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m114.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
            "Downloading watchdog-4.0.2-py3-none-manylinux2014_x86_64.whl (82 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.9/82.9 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: watchdog, tenacity, smmap, pydeck, gitdb, gitpython, streamlit\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 9.0.0\n",
            "    Uninstalling tenacity-9.0.0:\n",
            "      Successfully uninstalled tenacity-9.0.0\n",
            "Successfully installed gitdb-4.0.11 gitpython-3.1.43 pydeck-0.9.1 smmap-5.0.1 streamlit-1.38.0 tenacity-8.5.0 watchdog-4.0.2\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.0-py3-none-any.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.2)\n",
            "Downloading pyngrok-7.2.0-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.2.0\n"
          ]
        }
      ],
      "source": [
        "!pip install -U transformers sentencepiece\n",
        "!pip install bitsandbytes accelerate\n",
        "!pip install streamlit\n",
        "!pip install pyngrok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "SEsgGftQr-dL"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "microsoft/Phi-3.5-mini-instruct\n",
        "meta-llama/Meta-Llama-3.1-8B-Instruct\n",
        "google/gemma-2-9b-it\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFBPt5OkMMCx",
        "outputId": "b6c8b930-ff6f-4d26-c13c-590ee436a2df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "\n",
        "import streamlit as st\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "import random\n",
        "from huggingface_hub import login\n",
        "\n",
        "\n",
        "login(\"Hugging Face User Access Token\")\n",
        "\n",
        "name_model = 'google/gemma-2-9b-it'\n",
        "\n",
        "quantization_config = BitsAndBytesConfig(load_in_4bit=True)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(name_model)\n",
        "model = AutoModelForCausalLM.from_pretrained(name_model, quantization_config=quantization_config,\n",
        "                                                low_cpu_mem_usage=True,\n",
        "                                                device_map=\"auto\" )\n",
        "\n",
        "\n",
        "st.title(\"Institution Comparative Analysis Generator\")\n",
        "\n",
        "institution_name = st.text_input(\"Enter the name of the institution:\", \"Police\")\n",
        "\n",
        "use_random_countries = st.checkbox(\"Use random countries for comparison\")\n",
        "\n",
        "if use_random_countries:\n",
        "    country1 = st.text_input(\"Enter the first country:\", \"EGYPT\")\n",
        "    prompt = f\"\"\"\n",
        "    You will be provided with the name of an institution and its country.\n",
        "    Your task is to perform a concise comparative analysis by evaluating this institution and its counterparts in THREE COUNTRIES, including the provided country and two additional countries of your choice.\n",
        "    The analysis for each country should be structured as follows:\n",
        "\n",
        "    **[Country Name] [Institution Name]**\n",
        "\n",
        "    *   **Performance Metrics:**\n",
        "        *   **Response Time:** [Metric]\n",
        "        *   **Clearance Rate:** [Metric]\n",
        "        *   **Public Satisfaction:** [Metric]\n",
        "    *   **Key Risks:**\n",
        "        *   **Risk 1:** [Description]\n",
        "        *   **Risk 2:** [Description]\n",
        "        *   **Risk 3:** [Description]\n",
        "    *   **Strategies for Mitigating Risks:**\n",
        "        *   **Strategy 1:** [Description]\n",
        "        *   **Strategy 2:** [Description]\n",
        "        *   **Strategy 3:** [Description]\n",
        "\n",
        "    Provide the analysis for each country in a concise manner.\n",
        "    Do not include any additional observations or conclusions after the comparison.\n",
        "\n",
        "    Institution: {institution_name}, COUNTRY: {country1}, and TWO ADDITIONAL COUNTRIES of your choice.\n",
        "    \"\"\"\n",
        "\n",
        "else:\n",
        "    country1 = st.text_input(\"Enter the first country:\", \"EGYPT\")\n",
        "    country2 = st.text_input(\"Enter the second country:\", \"QATAR\")\n",
        "    country3 = st.text_input(\"Enter the third country:\", \"KSA\")\n",
        "    prompt = f\"\"\"\n",
        "    You will be given the name of an institution and its country.\n",
        "    Your task is to perform a concise comparative analysis by evaluating this institution and its counterparts in the following THREE COUNTRIES: {country1}, {country2} and {country3}.\n",
        "    The analysis for each country should be structured as follows:\n",
        "\n",
        "    **[Country Name] [Institution Name]**\n",
        "\n",
        "    *   **Performance Metrics:**\n",
        "        *   **Response Time:** [Metric]\n",
        "        *   **Clearance Rate:** [Metric]\n",
        "        *   **Public Satisfaction:** [Metric]\n",
        "    *   **Key Risks:**\n",
        "        *   **Risk 1:** [Description]\n",
        "        *   **Risk 2:** [Description]\n",
        "        *   **Risk 3:** [Description]\n",
        "    *   **Strategies for Mitigating Risks:**\n",
        "        *   **Strategy 1:** [Description]\n",
        "        *   **Strategy 2:** [Description]\n",
        "        *   **Strategy 3:** [Description]\n",
        "\n",
        "    Provide the analysis in a brief and concise manner for each country.\n",
        "    Do not add any observations or conclusions after the comparison.\n",
        "\n",
        "    Institution: {institution_name} and the THREE COUNTRIES: {country1}, {country2} and {country3}\n",
        "    \"\"\"\n",
        "\n",
        "if st.button(\"Generate Analysis\"):\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "\n",
        "    output = model.generate(**inputs,\n",
        "                            max_length=1500,\n",
        "                            num_return_sequences=1,\n",
        "                            do_sample=True,\n",
        "                            temperature=0.3,\n",
        "                            top_p=0.6,\n",
        "                            top_k=30\n",
        "                           )\n",
        "\n",
        "\n",
        "    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "\n",
        "    st.subheader(\"Generated Analysis:\")\n",
        "    st.write(generated_text)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XsKDzEoIM82c",
        "outputId": "de1efb61-9ccd-46d9-e606-a4992d5030eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Access your Streamlit app at NgrokTunnel: \"https://1dcc-34-87-33-218.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ],
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "# Set your authtoken\n",
        "ngrok.set_auth_token(\"Set your authtoken\")  # Replace with your actual authtoken\n",
        "\n",
        "# Open ngrok tunnel\n",
        "public_url = ngrok.connect(8501)\n",
        "\n",
        "!streamlit run app.py &>/dev/null &\n",
        "\n",
        "print(f\"Access your Streamlit app at {public_url}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "import random\n",
        "from huggingface_hub import login\n",
        "\n",
        "login(\"Hugging Face User Access Token\")\n",
        "\n",
        "name_model = 'google/gemma-2-9b-it'\n",
        "\n",
        "quantization_config = BitsAndBytesConfig(load_in_4bit=True)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(name_model)\n",
        "model = AutoModelForCausalLM.from_pretrained(name_model, quantization_config=quantization_config,\n",
        "                                                low_cpu_mem_usage=True,\n",
        "                                                device_map=\"auto\" )"
      ],
      "metadata": {
        "id": "KMWyg7piUl1x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252,
          "referenced_widgets": [
            "956ae0a5270c4ead9026778c6b649976",
            "1a436059fd294ec29befb72f488361d6",
            "20ca8750cc4f4d03bd443845db843d8c",
            "adbb5427c1d24287a1d21f1ede240cae",
            "ce74f073518e48608f5cdfa8eeac3b3e",
            "996c779d980d4e619bfb4142f2ba189d",
            "deccde103ce0401281cb3f83faca5e17",
            "afeee4cab3b843f3a284281d387ec8d7",
            "8364a7411a0642a3b84488d3955bdb86",
            "887c23eeaedc4b82838c128bda978a62",
            "78fcf2eee9594577905cd5edf8774a2e"
          ]
        },
        "collapsed": true,
        "outputId": "b919b383-39d6-498a-8025-ca39ddc1028d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: fineGrained).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "956ae0a5270c4ead9026778c6b649976"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "institution_name = 'Police'\n",
        "country1 = 'Egypt'\n",
        "country2 = 'KSA'\n",
        "country3 = 'UAE'\n",
        "prompt1 = f\"\"\"\n",
        "You will be given the name of an institution and its country.\n",
        "Your task is to perform a concise comparative analysis by evaluating this institution and its counterparts in the following THREE COUNTRIES: {country1}, {country2} and {country3}.\n",
        "The analysis for each country should be structured as follows:\n",
        "\n",
        "**[Country Name] [Institution Name]**\n",
        "\n",
        "*   **Performance Metrics:**\n",
        "    *   **Response Time:** [Metric]\n",
        "    *   **Clearance Rate:** [Metric]\n",
        "    *   **Public Satisfaction:** [Metric]\n",
        "*   **Key Risks:**\n",
        "    *   **Risk 1:** [Description]\n",
        "    *   **Risk 2:** [Description]\n",
        "    *   **Risk 3:** [Description]\n",
        "*   **Strategies for Mitigating Risks:**\n",
        "    *   **Strategy 1:** [Description]\n",
        "    *   **Strategy 2:** [Description]\n",
        "    *   **Strategy 3:** [Description]\n",
        "\n",
        "Provide the analysis in a brief and concise manner for each country.\n",
        "Do not add any observations or conclusions after the comparison.\n",
        "\n",
        "Institution: {institution_name} and the THREE COUNTRIES: {country1}, {country2} and {country3}\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "prompt = f\"\"\"\n",
        "You will be provided with the name of an institution and its country.\n",
        "Your task is to perform a concise comparative analysis by evaluating this institution and its counterparts in THREE COUNTRIES, including the provided country and two additional countries of your choice.\n",
        "The analysis for each country should be structured as follows:\n",
        "\n",
        "**[Country Name] [Institution Name]**\n",
        "\n",
        "*   **Performance Metrics:**\n",
        "    *   **Response Time:** [Metric]\n",
        "    *   **Clearance Rate:** [Metric]\n",
        "    *   **Public Satisfaction:** [Metric]\n",
        "*   **Key Risks:**\n",
        "    *   **Risk 1:** [Description]\n",
        "    *   **Risk 2:** [Description]\n",
        "    *   **Risk 3:** [Description]\n",
        "*   **Strategies for Mitigating Risks:**\n",
        "    *   **Strategy 1:** [Description]\n",
        "    *   **Strategy 2:** [Description]\n",
        "    *   **Strategy 3:** [Description]\n",
        "\n",
        "Provide the analysis for each country in a concise manner.\n",
        "Do not include any additional observations or conclusions after the comparison.\n",
        "\n",
        "Institution: {institution_name}, COUNTRY: {country1}, and TWO ADDITIONAL COUNTRIES of your choice.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "inputs = tokenizer(prompt1, return_tensors=\"pt\")\n",
        "\n",
        "output = model.generate(**inputs,\n",
        "                        max_length=1500,\n",
        "                        num_return_sequences=1,\n",
        "                        do_sample=True,\n",
        "                        temperature=0.3,\n",
        "                        top_p=0.6,\n",
        "                        top_k=30\n",
        "                        )\n",
        "\n",
        "# فك تشفير النص الناتج\n",
        "generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "print(generated_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_C68-NgUfGwa",
        "outputId": "4d1b2dd4-698b-477b-8fb9-dd02d416799e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1885: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/nn/modules.py:435: UserWarning: Input type into Linear4bit is torch.float16, but bnb_4bit_compute_dtype=torch.float32 (default). This will lead to slow inference or training speed.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "You will be given the name of an institution and its country.\n",
            "Your task is to perform a concise comparative analysis by evaluating this institution and its counterparts in the following THREE COUNTRIES: Egypt, KSA and UAE.\n",
            "The analysis for each country should be structured as follows:\n",
            "\n",
            "**[Country Name] [Institution Name]**\n",
            "\n",
            "*   **Performance Metrics:**\n",
            "    *   **Response Time:** [Metric]\n",
            "    *   **Clearance Rate:** [Metric]\n",
            "    *   **Public Satisfaction:** [Metric]\n",
            "*   **Key Risks:**\n",
            "    *   **Risk 1:** [Description]\n",
            "    *   **Risk 2:** [Description]\n",
            "    *   **Risk 3:** [Description]\n",
            "*   **Strategies for Mitigating Risks:**\n",
            "    *   **Strategy 1:** [Description]\n",
            "    *   **Strategy 2:** [Description]\n",
            "    *   **Strategy 3:** [Description]\n",
            "\n",
            "Provide the analysis in a brief and concise manner for each country.\n",
            "Do not add any observations or conclusions after the comparison.\n",
            "\n",
            "Institution: Police and the THREE COUNTRIES: Egypt, KSA and UAE\n",
            "## Egypt Police\n",
            "\n",
            "*   **Performance Metrics:**\n",
            "    *   **Response Time:** Average 15 minutes\n",
            "    *   **Clearance Rate:** 30%\n",
            "    *   **Public Satisfaction:** Low\n",
            "*   **Key Risks:**\n",
            "    *   **Risk 1:** Corruption and abuse of power\n",
            "    *   **Risk 2:** Lack of transparency and accountability\n",
            "    *   **Risk 3:** Understaffing and inadequate resources\n",
            "*   **Strategies for Mitigating Risks:**\n",
            "    *   **Strategy 1:** Implementing stricter anti-corruption measures\n",
            "    *   **Strategy 2:** Enhancing transparency through public reporting and oversight\n",
            "    *   **Strategy 3:** Investing in training and recruitment to increase personnel\n",
            "\n",
            "## KSA Police\n",
            "\n",
            "*   **Performance Metrics:**\n",
            "    *   **Response Time:** Average 10 minutes\n",
            "    *   **Clearance Rate:** 50%\n",
            "    *   **Public Satisfaction:** Moderate\n",
            "*   **Key Risks:**\n",
            "    *   **Risk 1:** Cultural and societal norms that may hinder reporting\n",
            "    *   **Risk 2:** Limited access to technology and resources\n",
            "    *   **Risk 3:** Dependence on traditional policing methods\n",
            "*   **Strategies for Mitigating Risks:**\n",
            "    *   **Strategy 1:** Raising awareness about crime reporting and victim support\n",
            "    *   **Strategy 2:** Investing in technology and infrastructure to improve efficiency\n",
            "    *   **Strategy 3:** Exploring innovative policing strategies and community engagement\n",
            "\n",
            "## UAE Police\n",
            "\n",
            "*   **Performance Metrics:**\n",
            "    *   **Response Time:** Average 5 minutes\n",
            "    *   **Clearance Rate:** 70%\n",
            "    *   **Public Satisfaction:** High\n",
            "*   **Key Risks:**\n",
            "    *   **Risk 1:** Rapid population growth and urbanization\n",
            "    *   **Risk 2:** Cybercrime and digital threats\n",
            "    *   **Risk 3:** Maintaining public trust in the face of evolving challenges\n",
            "*   **Strategies for Mitigating Risks:**\n",
            "    *   **Strategy 1:** Proactive policing and crime prevention initiatives\n",
            "    *   **Strategy 2:** Strengthening cybersecurity capabilities and awareness\n",
            "    *   **Strategy 3:** Fostering community partnerships and building trust\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "956ae0a5270c4ead9026778c6b649976": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1a436059fd294ec29befb72f488361d6",
              "IPY_MODEL_20ca8750cc4f4d03bd443845db843d8c",
              "IPY_MODEL_adbb5427c1d24287a1d21f1ede240cae"
            ],
            "layout": "IPY_MODEL_ce74f073518e48608f5cdfa8eeac3b3e"
          }
        },
        "1a436059fd294ec29befb72f488361d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_996c779d980d4e619bfb4142f2ba189d",
            "placeholder": "​",
            "style": "IPY_MODEL_deccde103ce0401281cb3f83faca5e17",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "20ca8750cc4f4d03bd443845db843d8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_afeee4cab3b843f3a284281d387ec8d7",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8364a7411a0642a3b84488d3955bdb86",
            "value": 4
          }
        },
        "adbb5427c1d24287a1d21f1ede240cae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_887c23eeaedc4b82838c128bda978a62",
            "placeholder": "​",
            "style": "IPY_MODEL_78fcf2eee9594577905cd5edf8774a2e",
            "value": " 4/4 [01:41&lt;00:00, 24.24s/it]"
          }
        },
        "ce74f073518e48608f5cdfa8eeac3b3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "996c779d980d4e619bfb4142f2ba189d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "deccde103ce0401281cb3f83faca5e17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "afeee4cab3b843f3a284281d387ec8d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8364a7411a0642a3b84488d3955bdb86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "887c23eeaedc4b82838c128bda978a62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78fcf2eee9594577905cd5edf8774a2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
